{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47b0adc9-3ba2-4433-aede-741786a926b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e6e0516-726e-4bb3-b804-10c2f886cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18088, 8)\n",
      "Number of unique JobTitles (raw):  9219\n",
      "Number of unique tokenized JobTitles:  9216\n",
      "Number of unique Users:  4907\n"
     ]
    }
   ],
   "source": [
    "df_title = pd.read_csv('../data/cb12/processed/df_title_MinorGroup200_tokenized.csv', sep=';')\n",
    "print(df_title.shape)\n",
    "print(\"Number of unique JobTitles (raw): \", len(df_title.JobTitle.unique()))\n",
    "print(\"Number of unique tokenized JobTitles: \", len(df_title.JobTitle_token.unique()))\n",
    "print(\"Number of unique Users: \", len(df_title.UserId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d91338da-b41c-4556-8efa-f8b8d3896d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1682\n"
     ]
    }
   ],
   "source": [
    "vocab_lemma_filtered = set(chain(chain.from_iterable([eval(x) for x in df_title['JobTitle_token_Id']])))\n",
    "print('Vocab size: {}'.format(len(vocab_lemma_filtered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66c7fd-f24d-41a5-a1be-42b622019ced",
   "metadata": {},
   "source": [
    "# Step1: Create file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2916abd-b32c-4fdb-9d25-3e4f1e8c145c",
   "metadata": {},
   "source": [
    "### titles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0029d0f7-e779-42de-bde3-583f3765cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids = []\n",
    "JobTitle_tokens = []\n",
    "JobTitle_tokens_idx = []\n",
    "MajorGroups = []\n",
    "MinorGroups = []\n",
    "DetailedOccupations = []\n",
    "\n",
    "Id = 0\n",
    "for idx, row in df_title.iterrows():\n",
    "    if row[\"JobTitle_token\"] not in JobTitle_tokens:\n",
    "        Ids.append(Id)\n",
    "        JobTitle_tokens.append(row[\"JobTitle_token\"])\n",
    "        JobTitle_tokens_idx.append(row[\"JobTitle_token_Id\"])\n",
    "        MajorGroups.append(row[\"MajorGroup\"])\n",
    "        MinorGroups.append(row[\"MinorGroup\"])\n",
    "        DetailedOccupations.append(row[\"DetailedOccupation\"])\n",
    "        Id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6be212a5-40a2-498e-bbef-1313501df1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 6)\n"
     ]
    }
   ],
   "source": [
    "titles = pd.DataFrame({\"Id\": Ids, \n",
    "                       \"MajorGroup\": MajorGroups, \n",
    "                       \"MinorGroup\": MinorGroups, \n",
    "                       \"DetailedOccupation\": DetailedOccupations, \n",
    "                       \"JobTitle_tokens\": JobTitle_tokens,\n",
    "                       \"JobTitle_tokens_idx\": JobTitle_tokens_idx})\n",
    "print(titles.shape)\n",
    "titles.to_csv('../data/cb12/graph/titles.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1727a26-5b14-4c35-b91b-85c911ca351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_JobTitle_tokens2Id = dict(zip(JobTitle_tokens, Ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a648ab-7bcd-4300-a25b-02500b63fea9",
   "metadata": {},
   "source": [
    "### title_title_transition.csv\n",
    "* transition\n",
    "* add self-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65c3467a-f0b8-494d-bee7-0766d415c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996\n",
      "13181\n",
      "0.04768256085361787\n",
      "20640\n",
      "21825\n"
     ]
    }
   ],
   "source": [
    "Weight = defaultdict(int)\n",
    "\n",
    "for filename, rows in df_title.groupby('UserId'):\n",
    "    titles_thisresume = rows['JobTitle_token'].tolist()\n",
    "    for i in range(len(titles_thisresume)):\n",
    "        if i < len(titles_thisresume)-1:\n",
    "            src = dict_JobTitle_tokens2Id[titles_thisresume[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[titles_thisresume[i+1]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "\n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "print(len([v for k, v in Weight.items() if k[0]==k[1]])/ len(Weight))\n",
    "\n",
    "\n",
    "for idx, row in titles.iterrows():\n",
    "    job = row[\"Id\"]\n",
    "    if (job,job) not in Weight:\n",
    "        Weight[(job,job)] += 1\n",
    "                                  \n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "Src = [edge[0] for edge in Weight.keys()]\n",
    "Dst = [edge[1] for edge in Weight.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8adfd09a-fcab-487f-96e3-5c00864caa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_title_transition = pd.DataFrame({\"Src\": Src, \"Dst\": Dst, \"Weight\": list(Weight.values())})\n",
    "title_title_transition.to_csv('../data/cb12/graph/title_title_transition_MinorGroup200.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85b4ac-16c3-4958-9025-2b405aa3c221",
   "metadata": {},
   "source": [
    "### title_title_transition_enhanced.csv\n",
    "* if two titles have the same tag, there is a bi-directional edge between them\n",
    "* add self-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68ddf4f0-c39f-4644-b8a5-e5e8cfa73876",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('../data/cb12/processed/Tags_MinorGroup200_200.txt', 'r')\n",
    "tags = f_in.readlines()\n",
    "tags = [t.strip('\\n') for t in tags]\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee4646ce-7a41-47b2-86ae-b1af1744cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996\n",
      "13181\n",
      "0.04768256085361787\n",
      "6477442\n",
      "7133880\n",
      "6477819\n",
      "7134257\n"
     ]
    }
   ],
   "source": [
    "Weight = defaultdict(int)\n",
    "for filename, rows in df_title.groupby('UserId'):\n",
    "    titles_thisresume = rows['JobTitle_token'].tolist()\n",
    "    for i in range(len(titles_thisresume)):\n",
    "        if i < len(titles_thisresume)-1:\n",
    "            src = dict_JobTitle_tokens2Id[titles_thisresume[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[titles_thisresume[i+1]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "\n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "print(len([v for k, v in Weight.items() if k[0]==k[1]])/ len(Weight))\n",
    "\n",
    "list_JobTitle_tokens = dict_JobTitle_tokens2Id.keys()\n",
    "for tag in tags:\n",
    "    list_JobTitle_hastag = [title for title in list_JobTitle_tokens if tag in title.split()]\n",
    "    for i in range(len(list_JobTitle_hastag)):\n",
    "        for j in range(len(list_JobTitle_hastag)):\n",
    "            src = dict_JobTitle_tokens2Id[list_JobTitle_hastag[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[list_JobTitle_hastag[j]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "\n",
    "for idx, row in titles.iterrows():\n",
    "    job = row[\"Id\"]\n",
    "    if (job,job) not in Weight:\n",
    "        Weight[(job,job)] += 1\n",
    "                                  \n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "\n",
    "Src = [edge[0] for edge in Weight.keys()]\n",
    "Dst = [edge[1] for edge in Weight.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ae39a09-af7d-46e5-9e26-2df057f6baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_title_transition = pd.DataFrame({\"Src\": Src, \"Dst\": Dst, \"Weight\": list(Weight.values())})\n",
    "title_title_transition.to_csv('../data/cb12/graph/title_title_transition_MinorGroup200_enhanced.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28fd9d-95ad-4f24-bdb2-30029ea398a4",
   "metadata": {},
   "source": [
    "### id_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "164a1b6a-88f0-40e4-a839-e68b02ab240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Tag2id = dict()\n",
    "\n",
    "with open('../data/cb12/graph/id_tag.txt', 'w') as f:\n",
    "    for idx, tag in enumerate(tags):\n",
    "        f.write(str(idx) + '\\t' + 'Tag_' + tag)\n",
    "        f.write('\\n')\n",
    "        dict_Tag2id[tag] = idx\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d0f41-0f60-4c70-babd-913811dcc85d",
   "metadata": {},
   "source": [
    "### id_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68ef376f-5d0b-426a-aaa1-7f756450a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of title: 9216\n"
     ]
    }
   ],
   "source": [
    "dict_title2id = dict()\n",
    "with open('../data/cb12/graph/id_title.txt', 'w') as f:\n",
    "    i = 0\n",
    "    for idx, title in enumerate(df_title.JobTitle_token.unique()):\n",
    "        title = '_'.join(title.split())\n",
    "        f.write(str(idx) + '\\t' + 'T_' + title)\n",
    "        f.write('\\n')\n",
    "        dict_title2id[title] = i\n",
    "        i+=1\n",
    "f.close()\n",
    "print('Number of title: {}'.format(len(dict_title2id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc8543-5392-4b39-9ce0-03e7fdfe57b1",
   "metadata": {},
   "source": [
    "### title_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24cdb1fc-dea1-40f8-8768-a9526273e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_title2feature = dict()\n",
    "with open('../data/cb12/graph/title_feature.txt', 'w') as f:\n",
    "    for idx, row in df_title.iterrows():\n",
    "        title = '_'.join(row['JobTitle_token'].split())\n",
    "        feature = row['JobTitle_token_Id']\n",
    "        if title not in dict_title2feature:\n",
    "            f.write(str(dict_title2id[title]) + '\\t' + feature)\n",
    "            f.write('\\n')\n",
    "            dict_title2feature[title] = feature\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aaa352-53a8-4068-a080-fb8700ee39cb",
   "metadata": {},
   "source": [
    "### title_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99588497-7138-41b9-af65-bec756a576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_title2label = dict()\n",
    "with open('../data/cb12/graph/title_label.txt', 'w') as f:\n",
    "    for idx, row in df_title.iterrows():\n",
    "        title = '_'.join(row['JobTitle_token'].split())\n",
    "        if title not in dict_title2label:\n",
    "            MinorGroup = row['MinorGroup']\n",
    "            MajorGroup = row['MajorGroup'] \n",
    "            f.write(str(dict_title2id[title]) + '\\t' + str(MinorGroup) + '\\t' + str(MajorGroup))\n",
    "            f.write('\\n')\n",
    "            dict_title2label[title] = MinorGroup\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543608b9-3ac5-42b3-aea3-a4532d0ccc96",
   "metadata": {},
   "source": [
    "### title_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6346d874-dd69-433b-9f09-3f07c68b3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tag(title, tags):\n",
    "    result = []\n",
    "    for tag in tags:\n",
    "        if tag in title.split():\n",
    "            title_ = '_'.join(title.split())\n",
    "            result.append(str(dict_title2id[title_]) + '\\t' + str(dict_Tag2id[tag]))\n",
    "            #result.append(str(title_) + '\\t' + str(tag))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed76b5dc-7393-4c88-80bd-afd2668abfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag = []\n",
    "for title in list(df_title.JobTitle_token.unique()):\n",
    "    title_tag.append(find_tag(title, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80c6b99e-311e-40ab-87bc-d6d6e2189e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cb12/graph/title_tag.txt', 'w') as f:\n",
    "    for row in title_tag:\n",
    "        for item in row:\n",
    "            t,r = item.split()\n",
    "            f.write(t + '\\t' + r)\n",
    "            f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb2f642-fc0e-4bee-9a79-d4c49f2475f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_tag = list(chain(chain.from_iterable(title_tag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbff229-7bc6-44f1-93a3-020c9bf4c811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
