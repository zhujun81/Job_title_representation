{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47b0adc9-3ba2-4433-aede-741786a926b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6e0516-726e-4bb3-b804-10c2f886cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18088, 8)\n",
      "Number of unique JobTitles (raw):  9219\n",
      "Number of unique tokenized JobTitles:  9216\n",
      "Number of unique Users:  4907\n"
     ]
    }
   ],
   "source": [
    "df_title = pd.read_csv('../data/cb12/processed/df_title_MinorGroup200_tokenized.csv', sep=';')\n",
    "print(df_title.shape)\n",
    "print(\"Number of unique JobTitles (raw): \", len(df_title.JobTitle.unique()))\n",
    "print(\"Number of unique tokenized JobTitles: \", len(df_title.JobTitle_token.unique()))\n",
    "print(\"Number of unique Users: \", len(df_title.UserId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d91338da-b41c-4556-8efa-f8b8d3896d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1682\n"
     ]
    }
   ],
   "source": [
    "vocab_lemma_filtered = set(chain(chain.from_iterable([eval(x) for x in df_title['JobTitle_token_Id']])))\n",
    "print('Vocab size: {}'.format(len(vocab_lemma_filtered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66c7fd-f24d-41a5-a1be-42b622019ced",
   "metadata": {},
   "source": [
    "# Step1: Create file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc069ab9-6bcf-4a7d-835c-ce224910bc0e",
   "metadata": {},
   "source": [
    "### titles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d984658-98f1-40a2-ac70-ad37a15569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids = []\n",
    "JobTitle_tokens = []\n",
    "JobTitle_tokens_idx = []\n",
    "MajorGroups = []\n",
    "MinorGroups = []\n",
    "DetailedOccupations = []\n",
    "\n",
    "Id = 0\n",
    "for idx, row in df_title.iterrows():\n",
    "    if row[\"JobTitle_token\"] not in JobTitle_tokens:\n",
    "        Ids.append(Id)\n",
    "        JobTitle_tokens.append(row[\"JobTitle_token\"])\n",
    "        JobTitle_tokens_idx.append(row[\"JobTitle_token_Id\"])\n",
    "        MajorGroups.append(row[\"MajorGroup\"])\n",
    "        MinorGroups.append(row[\"MinorGroup\"])\n",
    "        DetailedOccupations.append(row[\"DetailedOccupation\"])\n",
    "        Id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98d5eaa8-ddec-45e3-991b-bfa17da4fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 6)\n"
     ]
    }
   ],
   "source": [
    "titles = pd.DataFrame({\"Id\": Ids, \n",
    "                       \"MajorGroup\": MajorGroups, \n",
    "                       \"MinorGroup\": MinorGroups, \n",
    "                       \"DetailedOccupation\": DetailedOccupations, \n",
    "                       \"JobTitle_tokens\": JobTitle_tokens,\n",
    "                       \"JobTitle_tokens_idx\": JobTitle_tokens_idx})\n",
    "print(titles.shape)\n",
    "titles.to_csv('../data/cb12/graph/titles.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e62033d-99a8-4afc-834e-230ea31a41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_JobTitle_tokens2Id = dict(zip(JobTitle_tokens, Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8097bc3-3dbc-4115-90ef-188cc47c837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "32\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(titles.DetailedOccupation.unique()))\n",
    "print(len(titles.MinorGroup.unique()))\n",
    "print(len(titles.MajorGroup.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2041a-db4b-4904-9851-68cd652d5b60",
   "metadata": {},
   "source": [
    "### title_title_transition.csv\n",
    "* transition\n",
    "* add self-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e93e143-7a89-4504-9a0a-b093854f8acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996\n",
      "13181\n",
      "0.04768256085361787\n",
      "20640\n",
      "21825\n"
     ]
    }
   ],
   "source": [
    "Weight = defaultdict(int)\n",
    "\n",
    "for filename, rows in df_title.groupby('UserId'):\n",
    "    titles_thisresume = rows['JobTitle_token'].tolist()\n",
    "    for i in range(len(titles_thisresume)):\n",
    "        if i < len(titles_thisresume)-1:\n",
    "            src = dict_JobTitle_tokens2Id[titles_thisresume[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[titles_thisresume[i+1]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "\n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "print(len([v for k, v in Weight.items() if k[0]==k[1]])/ len(Weight))\n",
    "\n",
    "\n",
    "for idx, row in titles.iterrows():\n",
    "    job = row[\"Id\"]\n",
    "    if (job,job) not in Weight:\n",
    "        Weight[(job,job)] += 1\n",
    "                                  \n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "Src = [edge[0] for edge in Weight.keys()]\n",
    "Dst = [edge[1] for edge in Weight.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "94409db7-6ac7-4ad6-b683-c7b5fe1936df",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_title_transition = pd.DataFrame({\"Src\": Src, \"Dst\": Dst, \"Weight\": list(Weight.values())})\n",
    "title_title_transition.to_csv('../data/cb12/graph/title_title_transition_MinorGroup200.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c7914-2990-44f4-b9cb-028c575d557e",
   "metadata": {},
   "source": [
    "### title_title_transition_enhanced.csv\n",
    "* if two titles have the same tag, there is a bi-directional edge between them\n",
    "* add self-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1c4b4b3-17e9-4a5d-820d-08a4dfd9450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('../data/cb12/processed/Tags_MinorGroup200_200.txt', 'r')\n",
    "tags = f_in.readlines()\n",
    "tags = [t.strip('\\n') for t in tags]\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11fea27d-84e8-4cb3-9ac1-f9e6a80b4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996\n",
      "13181\n",
      "0.04768256085361787\n",
      "6477442\n",
      "7133880\n",
      "6477819\n",
      "7134257\n"
     ]
    }
   ],
   "source": [
    "Weight = defaultdict(int)\n",
    "for filename, rows in df_title.groupby('UserId'):\n",
    "    titles_thisresume = rows['JobTitle_token'].tolist()\n",
    "    for i in range(len(titles_thisresume)):\n",
    "        if i < len(titles_thisresume)-1:\n",
    "            src = dict_JobTitle_tokens2Id[titles_thisresume[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[titles_thisresume[i+1]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "\n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "print(len([v for k, v in Weight.items() if k[0]==k[1]])/ len(Weight))\n",
    "\n",
    "list_JobTitle_tokens = dict_JobTitle_tokens2Id.keys()\n",
    "for tag in tags:\n",
    "    list_JobTitle_hastag = [title for title in list_JobTitle_tokens if tag in title.split()]\n",
    "    for i in range(len(list_JobTitle_hastag)):\n",
    "        for j in range(len(list_JobTitle_hastag)):\n",
    "            src = dict_JobTitle_tokens2Id[list_JobTitle_hastag[i]]\n",
    "            dst = dict_JobTitle_tokens2Id[list_JobTitle_hastag[j]]\n",
    "            Weight[(src,dst)] += 1\n",
    "\n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "\n",
    "for idx, row in titles.iterrows():\n",
    "    job = row[\"Id\"]\n",
    "    if (job,job) not in Weight:\n",
    "        Weight[(job,job)] += 1\n",
    "                                  \n",
    "    \n",
    "print(len(Weight))\n",
    "print(np.sum(list(Weight.values())))\n",
    "\n",
    "\n",
    "Src = [edge[0] for edge in Weight.keys()]\n",
    "Dst = [edge[1] for edge in Weight.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43f737ed-3f30-4410-be6c-fb63ef305565",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_title_transition = pd.DataFrame({\"Src\": Src, \"Dst\": Dst, \"Weight\": list(Weight.values())})\n",
    "title_title_transition.to_csv('../data/cb12/graph/title_title_transition_MinorGroup200_enhanced.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbff229-7bc6-44f1-93a3-020c9bf4c811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
